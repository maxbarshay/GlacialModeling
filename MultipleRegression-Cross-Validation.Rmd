---
title: "MultipleRegression-Cross-Validation"
author: "Max Barshay"
date: "8/19/2021"
output: html_document
---


```{r}
library(coda)
library(rstan)
library(Rcpp)
source("~/Max/DBDA2E-utilities.R")
source("~/Max/MaxUtilities.R")
```


```{r}
MB_2015 = read.csv("~/Max/Mass_balance_data-2015.csv")
MB_2015
```

Standardizing the data based on all 25 sites. 



```{r}
full_x_coord = MB_2015[,"x.i93"] 
full_y_coord = MB_2015[,"y.i93"]
full_elevation = MB_2015[,"elvev.m.a.s.l."]
```


The model remains fixed throughout this whole process.


```{r}
modelString = "
  data {
    int<lower=1> N;
    int<lower=1> D;
    vector[D] x[N];
    vector[N] MB_W;
    real mean_MB_W;
    real sd_MB_W;
    real sd_x_coord;
    real sd_y_coord;
    real sd_elevation;

  }
  transformed data {
    real unifLo;
    real unifHi;
    real expLambda;
    real beta0sigma;
    real beta1sigma;
    real beta2sigma;
    real beta3sigma;
    unifLo = sd_MB_W/1000;
    unifHi = sd_MB_W*1000;
    expLambda = 1/29.0;
    beta1sigma = 10*fabs(sd_MB_W/sd_x_coord); // these priors are based off ideas from Doing Bayesian Data Analysis by Kruschke
    beta2sigma = 10*fabs(sd_MB_W/sd_y_coord);
    beta3sigma = 10*fabs(sd_MB_W/sd_elevation);
    beta0sigma = 10*fabs(mean_MB_W*sd_MB_W/sd_x_coord);

  }
  parameters {
    real beta0;
    real beta1;
    real beta2;
    real beta3;
    real<lower=0> nuMinusOne;
    real<lower=0.0001> sigma;
  }
  transformed parameters {
    real<lower=0> nu;
    nu = nuMinusOne + 1;
  }
  model {
    sigma ~ uniform(unifLo, unifHi);
    nuMinusOne ~ exponential(expLambda);
    beta0 ~ normal(0, beta0sigma);
    beta1 ~ normal(0, beta1sigma);
    beta2 ~ normal(0, beta2sigma);
    beta3 ~ normal(0, beta3sigma);
    for (i in 1:N){
      MB_W[i] ~ student_t(nu, beta0 + beta1 * x[i,1] + beta2 * x[i,2] + beta3 * x[i,3], sigma); // note that we have a t-distributed linear regression for robustness
    }
  }
"
```

Performing leave on out cross-validation (LOOCV).

```{r}
MR_RMSEs = numeric(25) # using RMSE as my metric
MR_Summaries = list()
for (i in 1:25){
  MB_subset = MB_2015[-i,]
  # I now standardize w.r.t. the 24 data observations that are not being held out as validation data
  x_coord = (MB_subset[,"x.i93"] - mean(MB_subset[,"x.i93"])) / sd(MB_subset[,"x.i93"])
  y_coord = (MB_subset[,"y.i93"] - mean(MB_subset[,"y.i93"])) / sd(MB_subset[,"y.i93"])
  elevation = (MB_subset[,"elvev.m.a.s.l."] - mean(MB_subset[,"elvev.m.a.s.l."])) / sd(MB_subset[,"elvev.m.a.s.l."])
  
  x = cbind(x_coord, y_coord, elevation)
  MB_W = MB_2015[-i,"bw"]
  XY_coords = cbind(x[,"x_coord"], x[,"x_coord"])
  distances = as.matrix(dist(XY_coords)) # 24x24 distance matrix based on the data standardized w.r.t. the 24 data observations

  # Now I standardize the original 25 measurements w.r.t. the 24 training observations so I don't leak information from the holdout observation into this iteration of LOOCV
  std_full_x_coord = (full_x_coord - mean(MB_subset[,"x.i93"])) / sd(MB_subset[,"x.i93"])
  std_full_y_coord = (full_y_coord - mean(MB_subset[,"y.i93"])) / sd(MB_subset[,"y.i93"])
  std_full_elevation = (full_elevation - mean(MB_subset[,"elvev.m.a.s.l."])) / sd(MB_subset[,"elvev.m.a.s.l."])
  
  dataList = list(
    N = length(MB_W),
    D = 3,
    x = x,
    MB_W = MB_W,
    mean_MB_W = mean(MB_W) ,
    sd_MB_W = sd(MB_W) ,
    sd_x_coord = sd(x_coord),
    sd_y_coord = sd(y_coord),
    sd_elevation = sd(elevation)
  )
  
  stanDso <- stan_model(model_code=modelString) 
  
  stanFit <- sampling( object=stanDso, 
                         data = dataList, 
                         #pars = parameters , # optional
                         chains = 5,
                         iter = 10000, # this could be more potentially 
                         warmup = 500, 
                         #init = initsList , # optional
                         thin = 1)
  
  mcmcCoda = mcmc.list(lapply( 1:ncol(stanFit) , 
                                   function(x) { mcmc(as.array(stanFit)[,x,]) })) # this is just for convenience
  
  summary = smryMCMC_MR(mcmcCoda)

  MCSE = summary[,"SD"] / sqrt(summary[,"ESS"])
  summary = cbind(summary, MCSE)
  
  MR_Summaries[[i]] = summary[,c("Mean", "Median", "Mode", "SD", "ESS", "HDImass", "HDIlow", "HDIhigh", "MCSE")]
  
  results = as.matrix(mcmcCoda, chains=T)
  
  # Now I make a posterior predictive distribution for the left out site
  N = length(results[,"beta0"])
  predictions = results[, "beta0"] + results[, "beta1"] * std_full_x_coord[i] + results[, "beta2"] * std_full_y_coord[i] + results[, "beta3"] * std_full_elevation[i] + (rt(N, results[,"nu"]) * results[,"sigma"])
  actual = MB_2015[i,"bw"]
  # I then take the RMSE for the actual mass balance and the posterior predictive distribution ***
  MR_RMSEs[i] = sqrt(mean((predictions - actual) ^ 2))
}
```

```{r}
MR_RMSEs
```

```{r}
MR_Summaries
```


```{r}
save(MR_RMSEs, file="MR_RMSEs.Rdata")
save(MR_Summaries, file="MR_Summaries.Rdata")
```



